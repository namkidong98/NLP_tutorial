{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## NLTK를 이용한 NER"
      ],
      "metadata": {
        "id": "tNjRT_AwmMQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SdFbVvymmYd",
        "outputId": "1fb8c6f6-997d-4aec-9456-bba52ac9c63d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy-xRQb2mrPM",
        "outputId": "c4e24e6b-bdb4-40da-ef44-01be1799083f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTjMuA1ejCbz",
        "outputId": "4349d3d8-e1dd-48fa-ee67-4e0d283027b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('James', 'NNP'), ('is', 'VBZ'), ('working', 'VBG'), ('at', 'IN'), ('Disney', 'NNP'), ('in', 'IN'), ('London', 'NNP')]\n"
          ]
        }
      ],
      "source": [
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "\n",
        "sentence = \"James is working at Disney in London\"\n",
        "# 토큰화 후 품사 태깅\n",
        "tokenized_sentence = pos_tag(word_tokenize(sentence))\n",
        "print(tokenized_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 개체명 인식\n",
        "ner_sentence = ne_chunk(tokenized_sentence)\n",
        "print(ner_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdajRVBNmQFw",
        "outputId": "6946dafc-b841-4abb-efa7-aa0dca045b39"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (PERSON James/NNP)\n",
            "  is/VBZ\n",
            "  working/VBG\n",
            "  at/IN\n",
            "  (ORGANIZATION Disney/NNP)\n",
            "  in/IN\n",
            "  (GPE London/NNP))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BiLSTM을 이용한 NER"
      ],
      "metadata": {
        "id": "WV48_KfVmQj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "COci1J0GmTEf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/12.%20RNN%20Sequence%20Labeling/dataset/train.txt\", filename=\"train.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3SND7T8mTts",
        "outputId": "bc85f092-b2a5-41d1-a301-0f8162120622"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('train.txt', <http.client.HTTPMessage at 0x7cf723229270>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 로드 & 토크나이징"
      ],
      "metadata": {
        "id": "f2WViU1g_AxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('train.txt', 'r')\n",
        "tagged_sentences = []\n",
        "sentence = []\n",
        "\n",
        "for line in f:\n",
        "    if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
        "        if len(sentence) > 0:\n",
        "            tagged_sentences.append(sentence)\n",
        "            sentence = []\n",
        "        continue\n",
        "    splits = line.split(' ') # 공백을 기준으로 속성을 구분한다.\n",
        "    splits[-1] = re.sub(r'\\n', '', splits[-1]) # 줄바꿈 표시 \\n을 제거한다.\n",
        "    word = splits[0].lower() # 단어들은 소문자로 바꿔서 저장한다.\n",
        "    sentence.append([word, splits[-1]]) # 단어와 개체명 태깅만 기록한다.\n",
        "\n",
        "print(\"전체 샘플 개수: \", len(tagged_sentences)) # 전체 샘플의 개수 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHXkiUSGm7B3",
        "outputId": "ae820ee2-a29c-4284-a3de-a6d65895c416"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 개수:  14041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tagged_sentences[0]) # 첫번째 샘플 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYJAuHemnG32",
        "outputId": "253723e4-c19b-4fe8-ee9e-36aaa22f14e1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['eu', 'B-ORG'], ['rejects', 'O'], ['german', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['british', 'B-MISC'], ['lamb', 'O'], ['.', 'O']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences, ner_tags = [], []\n",
        "for tagged_sentence in tagged_sentences: # 14,041개의 문장 샘플을 1개씩 불러온다.\n",
        "    sentence, tag_info = zip(*tagged_sentence) # 각 샘플에서 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장.\n",
        "    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.\n",
        "    ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장한다.\n",
        "\n",
        "print(sentences[0])\n",
        "print(ner_tags[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9DoIj3cn2-2",
        "outputId": "7dfcdc39-4ff4-4bb7-fc18-31ae7f387f46"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
            "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "eu, german, british에 대해서 ner_tags가 지정된 것을 확인할 수 있다(나머지는 O)"
      ],
      "metadata": {
        "id": "7dLKzMVS610i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentences, ner_tags, test_size=.2, random_state=777)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=.2, random_state=777)\n",
        "print('훈련 데이터의 개수 :', len(X_train))\n",
        "print('검증 데이터의 개수 :', len(X_valid))\n",
        "print('테스트 데이터의 개수 :', len(X_test))\n",
        "print('훈련 데이터 레이블의 개수 :', len(X_train))\n",
        "print('검증 데이터 레이블의 개수 :', len(X_valid))\n",
        "print('테스트 데이터 레이블의 개수 :', len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvFSIZERoISm",
        "outputId": "4b345297-01cf-4d93-d256-a578616c518b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 개수 : 8985\n",
            "검증 데이터의 개수 : 2247\n",
            "테스트 데이터의 개수 : 2809\n",
            "훈련 데이터 레이블의 개수 : 8985\n",
            "검증 데이터 레이블의 개수 : 2247\n",
            "테스트 데이터 레이블의 개수 : 2809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in X_train[:2]:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfPRpeSY7Hc8",
        "outputId": "01ad6d87-1bd8-49ba-b927-688cd3491d08"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['young', 'boys', '9', '1', '0', '8', '6', '19', '3']\n",
            "['hentgen', '(', '17-7', ')', 'surrendered', 'just', 'three', 'doubles', 'and', 'a', 'pair', 'of', 'singles', 'in', 'tossing', 'his', 'major-league', 'leading', 'ninth', 'complete', 'game', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocab 만들기"
      ],
      "metadata": {
        "id": "R7AuXtja_ET4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "word_list = []\n",
        "for sent in X_train:\n",
        "    for word in sent:\n",
        "      word_list.append(word)\n",
        "\n",
        "word_counts = Counter(word_list)\n",
        "print('총 단어수 :', len(word_counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7kWGLDh7JW7",
        "outputId": "b1f1b753-cdce-4103-8204-3ef7af1e2749"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 단어수 : 16742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "print('등장 빈도수 상위 10개 단어')\n",
        "print(vocab[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3mwUF2x7dBW",
        "outputId": "b985ce33-5e9b-4dd3-b9c8-322fadeb158c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "등장 빈도수 상위 10개 단어\n",
            "['the', ',', '.', 'of', 'in', 'to', 'a', ')', '(', 'and']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [For 데이터] Word_to_Index로 정수 인코딩"
      ],
      "metadata": {
        "id": "5ATsNolG_Gpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {}\n",
        "word_to_index['<PAD>'] = 0\n",
        "word_to_index['<UNK>'] = 1\n",
        "\n",
        "for index, word in enumerate(vocab) :\n",
        "  word_to_index[word] = index + 2\n",
        "\n",
        "vocab_size = len(word_to_index)\n",
        "print('패딩 토큰과 UNK 토큰을 고려한 단어 집합의 크기 :', vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rZNti6_7hKG",
        "outputId": "e81f6ac4-3335-4e8e-a508-80be9fc57747"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "패딩 토큰과 UNK 토큰을 고려한 단어 집합의 크기 : 16744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 <PAD>와 맵핑되는 정수 :', word_to_index['<PAD>'])\n",
        "print('단어 <UNK>와 맵핑되는 정수 :', word_to_index['<UNK>'])\n",
        "print('단어 the와 맵핑되는 정수 :', word_to_index['the'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F68kmeel7oEZ",
        "outputId": "eec7fb3c-f0a8-43b5-b665-249ea9a07764"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 <PAD>와 맵핑되는 정수 : 0\n",
            "단어 <UNK>와 맵핑되는 정수 : 1\n",
            "단어 the와 맵핑되는 정수 : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def texts_to_sequences(tokenized_X_data, word_to_index):\n",
        "  encoded_X_data = []\n",
        "  for sent in tokenized_X_data:\n",
        "    index_sequences = []\n",
        "    for word in sent:\n",
        "      try: # 사전에 있는 경우 해당 단어의 정수 인코딩 값으로 변환\n",
        "          index_sequences.append(word_to_index[word])\n",
        "      except KeyError: # OOV의 경우 UNK 토큰의 정수 인코딩 값으로 처리\n",
        "          index_sequences.append(word_to_index['<UNK>'])\n",
        "    encoded_X_data.append(index_sequences)\n",
        "  return encoded_X_data\n",
        "\n",
        "encoded_X_train = texts_to_sequences(X_train, word_to_index)\n",
        "encoded_X_valid = texts_to_sequences(X_valid, word_to_index)\n",
        "encoded_X_test = texts_to_sequences(X_test, word_to_index)\n",
        "\n",
        "for sent, encoded_sent in zip(X_train[:2], encoded_X_train[:2]):\n",
        "  print(sent)\n",
        "  print(encoded_sent)\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZV5TI1Q7qlF",
        "outputId": "4e819769-aff7-49ee-c4ea-d3a5673261b5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['young', 'boys', '9', '1', '0', '8', '6', '19', '3']\n",
            "[1260, 3215, 117, 17, 21, 123, 56, 539, 23]\n",
            "\n",
            "['hentgen', '(', '17-7', ')', 'surrendered', 'just', 'three', 'doubles', 'and', 'a', 'pair', 'of', 'singles', 'in', 'tossing', 'his', 'major-league', 'leading', 'ninth', 'complete', 'game', '.']\n",
            "[5456, 10, 8229, 9, 8230, 186, 84, 1815, 11, 8, 1073, 5, 421, 6, 8231, 35, 2043, 291, 790, 957, 267, 4]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [For 데이터] Index_to_word로 인코딩된 정수값을 다시 단어로 Decoding"
      ],
      "metadata": {
        "id": "g-hAvaYT_LEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {}\n",
        "for key, value in word_to_index.items():\n",
        "    index_to_word[value] = key\n",
        "\n",
        "decoded_sample = [index_to_word[word] for word in encoded_X_train[0]]\n",
        "print('기존의 첫번째 샘플 :', X_train[0])\n",
        "print('복원된 첫번째 샘플 :', decoded_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JYBKiPb7wPG",
        "outputId": "e9ec3f4a-3504-4e88-f870-9620976371f4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "기존의 첫번째 샘플 : ['young', 'boys', '9', '1', '0', '8', '6', '19', '3']\n",
            "복원된 첫번째 샘플 : ['young', 'boys', '9', '1', '0', '8', '6', '19', '3']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [For 레이블] Tag_to_Index로 label인 POS Tag를 정수 인코딩"
      ],
      "metadata": {
        "id": "ivPeEAdS_xuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블(여기서는 POS TAG)에 대한 정수 인코딩\n",
        "# y_train으로부터 존재하는 모든 태그들의 집합 구하기\n",
        "flatten_tags = [tag for sent in y_train for tag in sent] # y_train의 모든 문장에 대해 문장 안 tag들을 리스트로\n",
        "tag_vocab = list(set(flatten_tags))\n",
        "print('태그 집합 :', tag_vocab)\n",
        "print('태그 집합의 크기 :', len(tag_vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXl32kzc8Rbk",
        "outputId": "29387289-3326-4555-dd8f-0a1186bdb19f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "태그 집합 : ['O', 'B-MISC', 'I-PER', 'I-MISC', 'I-ORG', 'B-PER', 'B-LOC', 'B-ORG', 'I-LOC']\n",
            "태그 집합의 크기 : 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tag를 정수 인코딩 값으로 변환하는 작업\n",
        "tag_to_index = {}\n",
        "tag_to_index['<PAD>'] = 0 # UNK의 경우 이미 O로 처리되기 때문에 PAD만 추가\n",
        "\n",
        "for index, word in enumerate(tag_vocab) :\n",
        "  tag_to_index[word] = index + 1\n",
        "\n",
        "tag_vocab_size = len(tag_to_index)\n",
        "# print('패딩 토큰까지 포함된 태그 집합의 크기 :', tag_vocab_size)\n",
        "print('태그 집합 :', tag_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVQkZ4PJ8vdp",
        "outputId": "8ef1df33-f9ac-418d-b7f8-62d00e80b701"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "태그 집합 : {'<PAD>': 0, 'O': 1, 'B-MISC': 2, 'I-PER': 3, 'I-MISC': 4, 'I-ORG': 5, 'B-PER': 6, 'B-LOC': 7, 'B-ORG': 8, 'I-LOC': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "태그는 총 10개가 존재했다. 아래 4개에 대해 B, I로 2개씩 존재하고 <PAD>와 O를 추가해서 총 10개이다\n",
        "- PER : PERSON\n",
        "- LOC : LOCATION\n",
        "- ORG : ORGANIZATION\n",
        "- MISC : Miscellaneous(잡다)"
      ],
      "metadata": {
        "id": "2pbQeBk79T6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tag들의 sequence에서 tag의 정수 인덱스로 encoding하는 함수\n",
        "def encoding_label(sequence, tag_to_index):\n",
        "  label_sequence = []\n",
        "  for seq in sequence:\n",
        "    label_sequence.append([tag_to_index[tag] for tag in seq])\n",
        "  return label_sequence"
      ],
      "metadata": {
        "id": "3GRfqK5w9CGn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_y_train = texts_to_sequences(y_train, tag_to_index)\n",
        "encoded_y_valid = texts_to_sequences(y_valid, tag_to_index)\n",
        "encoded_y_test = texts_to_sequences(y_test, tag_to_index)"
      ],
      "metadata": {
        "id": "DQkeAsyd9NIk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('X 데이터 상위 2개')\n",
        "print(encoded_X_train[:2])\n",
        "print('-' * 50)\n",
        "print('y 데이터 상위 2개')\n",
        "print(encoded_y_train[:2])\n",
        "print('-' * 50)\n",
        "print('첫번째 샘플과 레이블의 길이')\n",
        "print(len(encoded_X_train[0]))\n",
        "print(len(encoded_y_train[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HZ3EuLh9Ob-",
        "outputId": "b4ec3457-b461-4f2b-b5fd-736e62e21a34"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X 데이터 상위 2개\n",
            "[[1260, 3215, 117, 17, 21, 123, 56, 539, 23], [5456, 10, 8229, 9, 8230, 186, 84, 1815, 11, 8, 1073, 5, 421, 6, 8231, 35, 2043, 291, 790, 957, 267, 4]]\n",
            "--------------------------------------------------\n",
            "y 데이터 상위 2개\n",
            "[[8, 5, 1, 1, 1, 1, 1, 1, 1], [6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
            "--------------------------------------------------\n",
            "첫번째 샘플과 레이블의 길이\n",
            "9\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [For 레이블] 정수 인코딩된 인덱스로부터 원래의 POS Tag를 복원(Decoding)"
      ],
      "metadata": {
        "id": "H9bESMSzAcmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_tag = {}\n",
        "for key, value in tag_to_index.items():\n",
        "  index_to_tag[value] = key"
      ],
      "metadata": {
        "id": "-ULgovknAjmJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_tag[0], index_to_tag[1], index_to_tag[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6d-KV1nAlNm",
        "outputId": "dd9401a7-24ba-49c6-9d1a-9bc02ab05ba2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('<PAD>', 'O', 'B-MISC')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding"
      ],
      "metadata": {
        "id": "q1LLGyANAwn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('샘플의 최대 길이 : %d' % max(len(l) for l in encoded_X_train))\n",
        "print('샘플의 평균 길이 : %f' % (sum(map(len, encoded_X_train))/len(encoded_X_train)))\n",
        "plt.hist([len(s) for s in encoded_X_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "v4N3R95D9PxT",
        "outputId": "0eb586ce-7dcf-4da6-cc22-de45e4022a57"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이 : 78\n",
            "샘플의 평균 길이 : 14.518420\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# max_len을 정하기 위해 해당 길이의 전체 비율을 체크하는 함수를 제작\n",
        "def below_threshold_len(max_len, nested_list):\n",
        "  count = 0\n",
        "  for sentence in nested_list:\n",
        "    if(len(sentence) <= max_len):\n",
        "        count = count + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"
      ],
      "metadata": {
        "id": "5_7cSgsG95Eq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대길이가 78이기 때문에 80으로 padding해도 되긴 함\n",
        "max_len = 80\n",
        "below_threshold_len(max_len, encoded_X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR2z-r3s9-xO",
        "outputId": "0832c5fd-c063-424b-8bd5-fb4b68b9956d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 중 길이가 80 이하인 샘플의 비율: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 50\n",
        "below_threshold_len(max_len, encoded_X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJP-7TWo-CaK",
        "outputId": "dd5f41a6-0fd7-4126-eeef-aa36bd76bb23"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 중 길이가 50 이하인 샘플의 비율: 99.67723984418475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# padding 함수\n",
        "def pad_sequences(sentences, max_len):\n",
        "    features = np.zeros((len(sentences), max_len), dtype=int) # 일단 max_len만큼 0으로 초기화하고\n",
        "    for index, sentence in enumerate(sentences):\n",
        "        if len(sentence) != 0:\n",
        "            features[index, :len(sentence)] = np.array(sentence)[:max_len] # sentence에 기존 값(정수 인코딩 sequence)는 그대로 덮어 써준다\n",
        "    return features"
      ],
      "metadata": {
        "id": "GeZBlhTe-DmY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_X_train = pad_sequences(encoded_X_train, max_len=max_len)\n",
        "padded_X_valid = pad_sequences(encoded_X_valid, max_len=max_len)\n",
        "padded_X_test = pad_sequences(encoded_X_test, max_len=max_len)\n",
        "\n",
        "padded_y_train = pad_sequences(encoded_y_train, max_len=max_len)\n",
        "padded_y_valid = pad_sequences(encoded_y_valid, max_len=max_len)\n",
        "padded_y_test = pad_sequences(encoded_y_test, max_len=max_len)\n",
        "\n",
        "print('훈련 데이터의 크기 :', padded_X_train.shape)\n",
        "print('검증 데이터의 크기 :', padded_X_valid.shape)\n",
        "print('테스트 데이터의 크기 :', padded_X_test.shape)\n",
        "print('-' * 30)\n",
        "print('훈련 데이터의 레이블 :', padded_y_train.shape)\n",
        "print('검증 데이터의 레이블 :', padded_y_valid.shape)\n",
        "print('테스트 데이터의 레이블 :', padded_y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qbyhs56-Pyw",
        "outputId": "58580b1c-0232-48a4-b9e9-b1bcee24dbcd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 크기 : (8985, 50)\n",
            "검증 데이터의 크기 : (2247, 50)\n",
            "테스트 데이터의 크기 : (2809, 50)\n",
            "------------------------------\n",
            "훈련 데이터의 레이블 : (8985, 50)\n",
            "검증 데이터의 레이블 : (2247, 50)\n",
            "테스트 데이터의 레이블 : (2809, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('훈련 데이터의 상위 샘플 2개')\n",
        "print(padded_X_train[:2])\n",
        "print('-' * 5 + '레이블' + '-' * 5)\n",
        "print(padded_y_train[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcXg2Rz4-hr8",
        "outputId": "60793b09-c9d2-4914-ac72-5703054778a8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 상위 샘플 2개\n",
            "[[1260 3215  117   17   21  123   56  539   23    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]\n",
            " [5456   10 8229    9 8230  186   84 1815   11    8 1073    5  421    6\n",
            "  8231   35 2043  291  790  957  267    4    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0]]\n",
            "-----레이블-----\n",
            "[[8 5 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [6 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling"
      ],
      "metadata": {
        "id": "tZsPBMhJA0yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"cpu와 cuda 중 다음 기기로 학습함:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yiei3F1n-jsW",
        "outputId": "f17955d4-7be0-47a6-b1fd-6ae9616bb465"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu와 cuda 중 다음 기기로 학습함: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NERTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers=2):\n",
        "        super(NERTagger, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True) # 단방향 GRU를 사용하는 경우\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True) # 양방향 LSTM을 사용하는 경우\n",
        "        # self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, seq_length)\n",
        "        embedded = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n",
        "        # gru_out, _ = self.gru(embedded)  # (batch_size, seq_length, hidden_dim)\n",
        "        lstm_out, _ = self.lstm(embedded)  # (batch_size, seq_length, hidden_dim*2)\n",
        "        # logits = self.fc(gru_out)  # (batch_size, seq_length, output_dim)\n",
        "        logits = self.fc(lstm_out)  # (batch_size, seq_length, output_dim)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "cyt44Nrg-pGf"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터와 레이블을 모두 tensor 형식으로 변환하고\n",
        "X_train_tensor = torch.tensor(padded_X_train, dtype=torch.long)\n",
        "y_train_tensor = torch.tensor(padded_y_train, dtype=torch.long)\n",
        "X_valid_tensor = torch.tensor(padded_X_valid, dtype=torch.long)\n",
        "y_valid_tensor = torch.tensor(padded_y_valid, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(padded_X_test, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(padded_y_test, dtype=torch.long)\n",
        "# TensorDataset으로 데이터셋을 구축 --> DataLoader로 Iterator 생성\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=32)\n",
        "valid_dataset = torch.utils.data.TensorDataset(X_valid_tensor, y_valid_tensor)\n",
        "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, shuffle=False, batch_size=32)\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=32)"
      ],
      "metadata": {
        "id": "ZKcDvDi3-sMa"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100 # 각 단어의 embedding 차원\n",
        "hidden_dim = 256    # BiLSTM의 hidden state의 차원 크기\n",
        "output_dim = tag_vocab_size # output의 차원은 전체 vocab 크기가 되어야 각 값들에 대한 확률값으로 나오고 그중 최대를 선택할 것\n",
        "learning_rate = 0.01\n",
        "num_epochs = 10\n",
        "num_layers = 2 # BiLSTM의 layer가 2개"
      ],
      "metadata": {
        "id": "3JIFLH9b-t1y"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model, loss, optimizer\n",
        "model = NERTagger(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0) # 0번째 index에 대한 loss 계산은 제외 = <PAD> 토큰은 모델 학습시 의미가 없으므로 손실 계산에서 무시\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "SO4k7tIc-uko"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(logits, labels, ignore_index=0):\n",
        "    # 예측 레이블을 구합니다.\n",
        "    predicted = torch.argmax(logits, dim=1) #\n",
        "\n",
        "    # 패딩 토큰은 무시합니다.\n",
        "    mask = (labels != ignore_index)\n",
        "\n",
        "    # 정답을 맞춘 경우를 집계합니다.\n",
        "    correct = (predicted == labels).masked_select(mask).sum().item()\n",
        "    total = mask.sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "def evaluate(model, valid_dataloader, criterion, device):\n",
        "    val_loss = 0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in valid_dataloader:\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "            # batch_X.shape = [batch_size, sequence_length, embedding_dim]\n",
        "            logits = model(batch_X) # logits.shape = [batch_size, sequence_length, output_dim(=vocab_size)]\n",
        "            loss = criterion(logits.view(-1, output_dim), batch_y.view(-1))\n",
        "            # logits.view(-1, output_dim) = [batch_size, sequence_length, output_dim]인 logits의 shape을 [batch_size * sequence_length, output_dim]으로 변경\n",
        "            # batch_y.view(-1) = [batch_size, sequence_length]인 batch_y의 shape을 [batch_size * sequence_length]로 변경\n",
        "            # batch_size * sequence_length는 total time step이고 배치 내의 모든 time step에 대해 각각의 경우 output_dim(vocab_size)마다의 로짓값이 softmax가 취해져서 확률값이 되고\n",
        "            # 그 확률값들 중에서 batch_y가 가리키는 정답 인덱스에 해당되는 확률값에 NLL(Negative Log-Likelihood)가 적용되며 이것이 손실값이 된다\n",
        "            # 그리고 정답 인덱스가 가리키는 확률값이 클수록 log_likelihood는 작아지며 그렇기 때문에 정답에 대한 확률이 높을수록 손실이 작게 계산되는 구조이다\n",
        "            # 그리고 이렇게 계산된 손실에 gradient를 계산하고 gradient를 줄이는 방향으로 학습을 진행하여 학습 후에 정답 인덱스에 대한 확률값이 높아지는 방향으로 파라미터가 학습되는 것이다\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_correct += calculate_accuracy(logits.view(-1, output_dim), batch_y.view(-1)) * batch_y.size(0)\n",
        "            val_total += batch_y.size(0)\n",
        "\n",
        "    val_accuracy = val_correct / val_total\n",
        "    val_loss /= len(valid_dataloader)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "oab59Ww5-xLD"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    train_loss = 0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    model.train()\n",
        "    for batch_X, batch_y in train_dataloader:\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device) # GPU에 올리고\n",
        "        logits = model(batch_X) # Forward Pass\n",
        "        loss = criterion(logits.view(-1, output_dim), batch_y.view(-1)) # logits을 실제 정답(레이블)과 비교하여 CrossEntropyLoss를 계산하고\n",
        "\n",
        "        optimizer.zero_grad() # 이전에 계산되어 있는 gradient를 초기화한 후\n",
        "        loss.backward()       # Backward pass: 해당 batch에서 계산된 손실(loss)를 바탕으로 모든 파라미터에 대한 gradient를 계산\n",
        "        optimizer.step()      # 계산된 gradient로 parameter update를 수행\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        train_correct += calculate_accuracy(logits.view(-1, output_dim), batch_y.view(-1)) * batch_y.size(0)\n",
        "        train_total += batch_y.size(0)\n",
        "\n",
        "    train_accuracy = train_correct / train_total\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    # Validation\n",
        "    val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "    # 검증 손실이 최소일 때 체크포인트 저장\n",
        "    if val_loss < best_val_loss:\n",
        "        print(f'Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. 체크포인트를 저장합니다.')\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'best_model_checkpoint.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwb6AOOe-1jh",
        "outputId": "ddb4617a-cfff-4960-9c1d-1928b2dbcd5e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10:\n",
            "Train Loss: 0.4269, Train Accuracy: 0.8846\n",
            "Validation Loss: 0.2386, Validation Accuracy: 0.9324\n",
            "Validation loss improved from inf to 0.2386. 체크포인트를 저장합니다.\n",
            "Epoch 2/10:\n",
            "Train Loss: 0.1334, Train Accuracy: 0.9612\n",
            "Validation Loss: 0.1761, Validation Accuracy: 0.9529\n",
            "Validation loss improved from 0.2386 to 0.1761. 체크포인트를 저장합니다.\n",
            "Epoch 3/10:\n",
            "Train Loss: 0.0595, Train Accuracy: 0.9827\n",
            "Validation Loss: 0.2337, Validation Accuracy: 0.9512\n",
            "Epoch 4/10:\n",
            "Train Loss: 0.0357, Train Accuracy: 0.9892\n",
            "Validation Loss: 0.2276, Validation Accuracy: 0.9548\n",
            "Epoch 5/10:\n",
            "Train Loss: 0.0235, Train Accuracy: 0.9929\n",
            "Validation Loss: 0.2273, Validation Accuracy: 0.9567\n",
            "Epoch 6/10:\n",
            "Train Loss: 0.0225, Train Accuracy: 0.9930\n",
            "Validation Loss: 0.2293, Validation Accuracy: 0.9563\n",
            "Epoch 7/10:\n",
            "Train Loss: 0.0211, Train Accuracy: 0.9934\n",
            "Validation Loss: 0.2260, Validation Accuracy: 0.9563\n",
            "Epoch 8/10:\n",
            "Train Loss: 0.0194, Train Accuracy: 0.9937\n",
            "Validation Loss: 0.2354, Validation Accuracy: 0.9581\n",
            "Epoch 9/10:\n",
            "Train Loss: 0.0215, Train Accuracy: 0.9933\n",
            "Validation Loss: 0.2222, Validation Accuracy: 0.9583\n",
            "Epoch 10/10:\n",
            "Train Loss: 0.0181, Train Accuracy: 0.9943\n",
            "Validation Loss: 0.2458, Validation Accuracy: 0.9573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 로드\n",
        "model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n",
        "\n",
        "# 모델을 device에 올립니다.\n",
        "model.to(device)\n",
        "\n",
        "# 검증 데이터에 대한 정확도(accuracy)와 손실(loss) 계산\n",
        "val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n",
        "\n",
        "print(f'Best model validation loss: {val_loss:.4f}')\n",
        "print(f'Best model validation accuracy: {val_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7O3Od1QP-2ug",
        "outputId": "b1f0d626-bd84-47d9-e169-210af85876a4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-7865f128b618>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model validation loss: 0.1761\n",
            "Best model validation accuracy: 0.9529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터에 대한 정확도와 손실 계산\n",
        "test_loss, test_accuracy = evaluate(model, test_dataloader, criterion, device)\n",
        "\n",
        "print(f'Best model test loss: {test_loss:.4f}')\n",
        "print(f'Best model test accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "carNO4c6-4pC",
        "outputId": "060e24f6-3934-4c66-a581-e3e095be031c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model test loss: 0.1707\n",
            "Best model test accuracy: 0.9536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_labels(text, model, word_to_ix, index_to_tag, max_len=150):\n",
        "    # 단어 토큰화\n",
        "    tokens = text.split()\n",
        "\n",
        "    # 정수 인코딩\n",
        "    token_indices = [word_to_ix.get(token, 1) for token in tokens]\n",
        "\n",
        "    # 패딩\n",
        "    token_indices_padded = np.zeros(max_len, dtype=int)\n",
        "    token_indices_padded[:len(token_indices)] = token_indices[:max_len]\n",
        "\n",
        "    # 텐서로 변환\n",
        "    input_tensor = torch.tensor(token_indices_padded, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    # 모델의 입력으로 사용하고 예측값 리턴\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)\n",
        "\n",
        "    # 가장 값이 높은 인덱스를 예측값으로 선택\n",
        "    predicted_indices = torch.argmax(logits, dim=-1).squeeze(0).tolist()\n",
        "\n",
        "    # 패딩 토큰 제거\n",
        "    predicted_indices_no_pad = predicted_indices[:len(tokens)]\n",
        "\n",
        "    # 패딩 토큰을 제외하고 정수 시퀀스를 예측 시퀀스로 변환\n",
        "    predicted_tags = [index_to_tag[index] for index in predicted_indices_no_pad]\n",
        "\n",
        "    return predicted_tags"
      ],
      "metadata": {
        "id": "pJjEC8Cg-6qT"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aojkgXLn-7-d",
        "outputId": "e2969446-d519-473d-8b50-91538adf8ef4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['feyenoord', 'rotterdam', 'suffered', 'an', 'early', 'shock', 'when', 'they', 'went', '1-0', 'down', 'after', 'four', 'minutes', 'against', 'de', 'graafschap', 'doetinchem', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = ' '.join(X_test[0])\n",
        "print(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFmY10QdEDxA",
        "outputId": "0595d464-e74a-4cc7-e904-2dbf0cb7ece4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feyenoord rotterdam suffered an early shock when they went 1-0 down after four minutes against de graafschap doetinchem .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_tags = predict_labels(sample, model, word_to_index, index_to_tag)\n",
        "print('예측 :', predicted_tags)\n",
        "print('실제값 :', y_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oK_2SlM--Nw",
        "outputId": "ce6a2958-4996-46d4-a910-0c69b7e8b402"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 : ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'B-MISC', 'I-PER', 'O']\n",
            "실제값 : ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O']\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "임베딩 층(Embedding Layer)는 룩업(Lookup) 테이블이다\n",
        "- 단어(text) -> 단어에 부여된 고유한 정수값(index) -> 임베딩 층 통과 -> 밀집 벡터(Dense Vector)\n",
        "- 즉, Embedding Layer는 특정 정수(index)를 특정 밀집 벡터(dense vector)에 맵핑하는 역할이며, 인공 신경망의 학습 과정에서 가중치가 학습되는 것과 같은 방식으로 밀집 벡터가 훈련된다"
      ],
      "metadata": {
        "id": "hCA7dBXTEth9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Embedding Layer"
      ],
      "metadata": {
        "id": "ZNKl3hp4IpLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Layer의 Lookup_Table 원리 이해하기"
      ],
      "metadata": {
        "id": "oyeEpAKDHluY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = 'you need to know how to code'\n",
        "\n",
        "wordset = set(train_data.split()) # train_data로부터 중복 제거한 단어 집합을 생성\n",
        "\n",
        "vocab = {word : i + 2 for i, word in enumerate(wordset)} # 2부터 시작해서 각 단어에 정수 인덱스를 부여\n",
        "vocab['<unk>'] = 0 # 0은 unknown token\n",
        "vocab['<pad>'] = 1 # 1은 padding token\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Azw58eaFZDs",
        "outputId": "9cc629b2-f6ca-42c0-b726-6c7d16457b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'need': 2, 'how': 3, 'you': 4, 'to': 5, 'know': 6, 'code': 7, '<unk>': 0, '<pad>': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 단어 집합의 크기만큼의 행을 가지는 테이블 생성.\n",
        "embedding_table = torch.FloatTensor([\n",
        "                               [ 0.0,  0.0,  0.0],  # <unk> : 0\n",
        "                               [ 0.0,  0.0,  0.0],  # <pad> : 1\n",
        "                               [ 0.2,  0.9,  0.3],  # need  : 2\n",
        "                               [ 0.1,  0.5,  0.7],  # how   : 3\n",
        "                               [ 0.2,  0.1,  0.8],  # you   : 4\n",
        "                               [ 0.4,  0.1,  0.1],  # to    : 5\n",
        "                               [ 0.1,  0.8,  0.9],  # know  : 6\n",
        "                               [ 0.6,  0.1,  0.1]]) # code  : 7"
      ],
      "metadata": {
        "id": "--vqY3QvF3bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AqwMLzGEEqg",
        "outputId": "8b737243-52e1-4164-c6c2-780a9a96acd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 2, 5, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "sample = 'you need to run'.split()\n",
        "index = []\n",
        "\n",
        "for word in sample:\n",
        "  # 각 단어에 대해 Vocab의 정수 인덱스로 변환\n",
        "  try:\n",
        "    index.append(vocab[word])\n",
        "  # Vocab에 없는 단어에 대해서는 <unk>으로\n",
        "  except KeyError:\n",
        "    index.append(vocab['<unk>'])\n",
        "\n",
        "# embedding_table이 tensor이기 때문에 tensor 타입으로 변형\n",
        "index = torch.LongTensor(index)\n",
        "index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# row(단어 개수)는 index(4, 2, 5, 0)를 참조하고 그 때마다 col(임베딩 벡터의 차원)은 all(:)\n",
        "lookup_result = embedding_table[index, :]\n",
        "print(lookup_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muUqlUjiHFYl",
        "outputId": "37c48414-77ac-4f76-a670-f56d78745223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2000, 0.1000, 0.8000],\n",
            "        [0.2000, 0.9000, 0.3000],\n",
            "        [0.4000, 0.1000, 0.1000],\n",
            "        [0.0000, 0.0000, 0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "tensor([[0.2000, 0.1000, 0.8000],   # you\n",
        "        [0.2000, 0.9000, 0.3000],   # need\n",
        "        [0.4000, 0.1000, 0.1000],   # to\n",
        "        [0.0000, 0.0000, 0.0000]])  # <unk>\n",
        "```"
      ],
      "metadata": {
        "id": "bUeTvgcNGwKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nn.Embedding()으로 임베딩 층(Embedding Layer) 사용하기"
      ],
      "metadata": {
        "id": "_VKRNFn5Hshn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = 'you need to know how to code'\n",
        "\n",
        "wordset = set(train_data.split()) # train_data로부터 중복 제거한 단어 집합을 생성\n",
        "\n",
        "vocab = {word : i + 2 for i, word in enumerate(wordset)} # 2부터 시작해서 각 단어에 정수 인덱스를 부여\n",
        "vocab['<unk>'] = 0 # 0은 unknown token\n",
        "vocab['<pad>'] = 1 # 1은 padding token\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGRK12ToGi0U",
        "outputId": "18599d5d-989a-4fe5-bfb8-cbacf944892f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'need': 2, 'how': 3, 'you': 4, 'to': 5, 'know': 6, 'code': 7, '<unk>': 0, '<pad>': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=3, padding_idx=1)\n",
        "# num_embeddings : 임베딩할 단어의 개수\n",
        "# embedding_dim : 임베딩할 벡터의 차원\n",
        "# padding_idx : 패딩을 위한 토큰의 인덱스"
      ],
      "metadata": {
        "id": "8-2HYDj3H2N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer.weight)\n",
        "# 앞에서는 임의로 생성했던 Lookup Table이 nn.Embedding으로 생성된 것을 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkyaLfmxH924",
        "outputId": "fa45308b-dced-44d7-ebe3-74814cf239da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.3912,  0.2304, -0.2282],\n",
            "        [ 0.0000,  0.0000,  0.0000],\n",
            "        [-1.2417,  0.6831,  1.2010],\n",
            "        [-0.6814,  0.9481,  0.9033],\n",
            "        [ 1.3358,  0.1982,  0.9304],\n",
            "        [ 0.4873, -0.0161, -0.5158],\n",
            "        [ 1.5266, -1.1556,  0.5876],\n",
            "        [-2.0050, -1.1502, -0.2996]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Pretrained Word Embedding"
      ],
      "metadata": {
        "id": "fBEdKtRaImy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnklbulDIHaB",
        "outputId": "cea47a12-684b-4fc3-dbd8-63b175fb3b08"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pretrained Word Embedding을 사용하지 않는 경우"
      ],
      "metadata": {
        "id": "90-WbFXiL8kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "import gensim\n",
        "\n",
        "# 7개의 문장과 긍/부정 판단을 위한 레이블 데이터 생성\n",
        "sentences = ['nice great best amazing',\n",
        "             'stop lies',\n",
        "             'pitiful nerd',\n",
        "             'excellent work',\n",
        "             'supreme quality',\n",
        "             'bad',\n",
        "             'highly respectable']\n",
        "y_train = [1, 0, 0, 1, 1, 0, 1]"
      ],
      "metadata": {
        "id": "paunznMUIy-a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences = [sent.split() for sent in sentences]\n",
        "print('단어 토큰화 된 결과 :', tokenized_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQYQ-h3BJCaL",
        "outputId": "2f73aea1-8f24-4c12-d312-cf925daa170e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화 된 결과 : [['nice', 'great', 'best', 'amazing'], ['stop', 'lies'], ['pitiful', 'nerd'], ['excellent', 'work'], ['supreme', 'quality'], ['bad'], ['highly', 'respectable']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = []\n",
        "# 모든 문장의 토큰화된 단어를 word_list에 넣음\n",
        "for sent in tokenized_sentences:\n",
        "  for word in sent:\n",
        "    word_list.append(word)\n",
        "\n",
        "word_counts = Counter(word_list)\n",
        "print('총 단어수 :', len(word_counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PTmb6abJKou",
        "outputId": "3c6c757b-4e29-4a11-d0de-05ab26f5ed09"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 단어수 : 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 등장 빈도순으로 정렬\n",
        "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCZjjBVGJYng",
        "outputId": "dd3b725c-69f8-463f-f0ab-b7e0af139142"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nice', 'great', 'best', 'amazing', 'stop', 'lies', 'pitiful', 'nerd', 'excellent', 'work', 'supreme', 'quality', 'bad', 'highly', 'respectable']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {}\n",
        "word_to_index['<PAD>'] = 0\n",
        "word_to_index['<UNK>'] = 1\n",
        "\n",
        "for index, word in enumerate(vocab):\n",
        "  word_to_index[word] = index + 2\n",
        "\n",
        "vocab_size = len(word_to_index)\n",
        "print(\"패딩 토큰, UNK 토큰을 고려한 단어 집합의 크기 :\", vocab_size) # 15 + 2(PAD, UNK)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcco-Oy8JfwE",
        "outputId": "fb884f7e-a6cf-4045-de3b-765307acd4fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "패딩 토큰, UNK 토큰을 고려한 단어 집합의 크기 : 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def texts_to_sequences(tokenized_X_data, word_to_index):\n",
        "  encoded_X_data = []\n",
        "  for sent in tokenized_X_data:\n",
        "    index_sequences = []\n",
        "    for word in sent: # 각 문장의 단어에 대해서\n",
        "      try:\n",
        "        index_sequences.append(word_to_index[word]) # 사전 내 단어에 할당된 index를 index_sequences에 추가\n",
        "      except KeyError: # OOV(사전에 없는 경우)\n",
        "        index_sequences.append(word_to_index['<UNK>']) # UNK 토큰에 할당된 index를 index_sequences에 추가\n",
        "    encoded_X_data.append(index_sequences)\n",
        "  return encoded_X_data # 각 문장마다 index sequence로 변환한 것들의 모음(리스트)\n",
        "\n",
        "X_encoded = texts_to_sequences(tokenized_sentences, word_to_index)\n",
        "print(X_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VUPCOfaKAaP",
        "outputId": "f4941101-c63f-4a7a-e2dd-fd6a06903b22"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 3, 4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14], [15, 16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in X_encoded)\n",
        "print('최대 길이 :', max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxknD_FeK85L",
        "outputId": "d762a36d-0d38-460a-cf04-b33528774778"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최대 길이 : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequences(sentences, max_len):\n",
        "  features = np.zeros((len(sentences), max_len), dtype=int)\n",
        "  for index, sentence in enumerate(sentences):\n",
        "    if len(sentence) != 0:\n",
        "      features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
        "  return features\n",
        "\n",
        "X_train = pad_sequences(X_encoded, max_len)\n",
        "y_train = np.array(y_train)\n",
        "print('패딩 결과 :')\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCY63fR3L1FQ",
        "outputId": "1c388d9a-256e-4aaa-d103-6f797e7cb405"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "패딩 결과 :\n",
            "[[ 2  3  4  5]\n",
            " [ 6  7  0  0]\n",
            " [ 8  9  0  0]\n",
            " [10 11  0  0]\n",
            " [12 13  0  0]\n",
            " [14  0  0  0]\n",
            " [15 16  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RO2I2nyqMTE",
        "outputId": "5c08072c-9787-4ddc-f1ad-1aef515dc839"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "glEIsiLLf_4I"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(SimpleModel, self).__init__() # nn.Module의 __init__을 상속 받고\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc = nn.Linear(embedding_dim * max_len, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x) # shape : (batch_size, sentence_length, embedding_dim)\n",
        "    flattened = self.flatten(embedded) # shape : (batch_size, sentence_length * embedding_dim)\n",
        "    output = self.fc(flattened) # shape : (batch_size, 1)\n",
        "    return self.sigmoid(output)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "embedding_dim = 100\n",
        "simple_model = SimpleModel(vocab_size, embedding_dim).to(device)"
      ],
      "metadata": {
        "id": "7wO7_duygftX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = Adam(simple_model.parameters())"
      ],
      "metadata": {
        "id": "u0JHnFTDgfpG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.long), torch.tensor(y_train, dtype=torch.float32))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2)"
      ],
      "metadata": {
        "id": "rG8-F-f5gfkL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataloader)) # 7개의 데이터를 batch_size 2로 하면 총 4번의 iteration이 된다"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2rgP9v2gffn",
        "outputId": "e76b25df-f3b8-4a65-ff7d-b1dfb1d469de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "  for inputs, targets in train_dataloader:\n",
        "    inputs, targets = inputs.to(device), targets.to(device) # GPU에 해당 batch의 input과 target을 올리고\n",
        "\n",
        "    optimizer.zero_grad()                   # 이전 epoch에서 계산된 기울기를 초기화\n",
        "    outputs = simple_model(inputs).view(-1) # 모델의 예측 계산 & 1차원 텐서로 변환\n",
        "    loss = criterion(outputs, targets)      # 손실값 계산\n",
        "    loss.backward()                         # 손실값을 토대로 각 파라미터 업데이트에 필요한 기울기 계산\n",
        "\n",
        "    optimizer.step()                        # 계산된 기울기를 바탕으로 파라미터 업데이트\n",
        "  print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjOF4ZdSgfZn",
        "outputId": "982a3f79-a4a9-4868-c4f2-fd3e14429f81"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.1613306999206543\n",
            "Epoch 2, Loss: 0.8831257224082947\n",
            "Epoch 3, Loss: 0.6458916068077087\n",
            "Epoch 4, Loss: 0.47528305649757385\n",
            "Epoch 5, Loss: 0.3627965748310089\n",
            "Epoch 6, Loss: 0.29160618782043457\n",
            "Epoch 7, Loss: 0.24681179225444794\n",
            "Epoch 8, Loss: 0.21781857311725616\n",
            "Epoch 9, Loss: 0.1976604014635086\n",
            "Epoch 10, Loss: 0.18192654848098755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pretrained Word Embedding을 사용하는 경우"
      ],
      "metadata": {
        "id": "5lI9AEx3MDLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1Av37IVBQAAntSe1X3MOAl5gvowQzd2_j"
      ],
      "metadata": {
        "id": "sMqOYv3rMFa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사전 학습된 Word2Vec 모델 로드\n",
        "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ],
      "metadata": {
        "id": "-eBjYTaxj3zi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 300)) # 사용하는 Word2Vec 모델이 300차원이기 때문에 300차원으로 설정, 다르면 오류 발생\n",
        "print('임베딩 행렬의 크기 :', embedding_matrix.shape) # row가 어휘의 개수, col이 각 어휘별 임베딩 차원"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrwn1njUj6q7",
        "outputId": "5f8f86cf-9f07-4e38-b7c5-f4df4ed7f96b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "임베딩 행렬의 크기 : (17, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 해당하는 단어가 pretrained Word2Vec에 있는 단어이면, 그 단어에 대한 사전 학습된 임베딩 벡터를 반환하도록\n",
        "def get_vector(word):\n",
        "    if word in word2vec_model:\n",
        "        return word2vec_model[word]\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "yeJcqJy6j8La"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# <PAD>를 위한 0번과 <UNK>를 위한 1번은 실제 단어가 아니므로 맵핑에서 제외\n",
        "for word, i in word_to_index.items():\n",
        "    if i > 2: # 0, 1은 <PAD>, <UNK>이므로\n",
        "      temp = get_vector(word)\n",
        "      if temp is not None:\n",
        "          embedding_matrix[i] = temp"
      ],
      "metadata": {
        "id": "z-T85yj8j9St"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# <PAD>나 <UNK>의 경우는 사전 훈련된 임베딩이 들어가지 않아서 0벡터임\n",
        "print(embedding_matrix[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qApMiHc_j-dO",
        "outputId": "75dcdea0-89ec-43a4-84b5-0b3229781e66"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index['great']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwvEnUpij_nP",
        "outputId": "4ffb2fd1-2677-4fa7-8074-f0c469989315"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec_model에서 'great'의 임베딩 벡터\n",
        "# embedding_matrix[3]이 일치하는지 체크\n",
        "np.all(word2vec_model['great'] == embedding_matrix[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLghUcEDkAlq",
        "outputId": "d5d42de4-c84b-4a80-a480-bb4ab0a40ec9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model['great'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4i5ha0Hl-U2",
        "outputId": "0f5d7f56-47ba-4eb6-cda8-a0300757edff"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PretrainedEmbeddingModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(PretrainedEmbeddingModel, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "    self.embedding.weight.requires_grad = True\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc = nn.Linear(embedding_dim*max_len, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    flattened = self.flatten(embedded)\n",
        "    output = self.fc(flattened)\n",
        "    return self.sigmoid(output)"
      ],
      "metadata": {
        "id": "7PP_NDzbmAPw"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embedding_model = PretrainedEmbeddingModel(vocab_size, 300).to(device)"
      ],
      "metadata": {
        "id": "pXfBjkbYpKLF"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimzer = Adam(pretrained_embedding_model.parameters())"
      ],
      "metadata": {
        "id": "QXk-fMYLpPz9"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.long), torch.tensor(y_train, dtype=torch.float32))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2)"
      ],
      "metadata": {
        "id": "6bRf8DCwpWeH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "  for inputs, targets in train_dataloader:\n",
        "    inputs, targets = inputs.to(device), targets.to(device) # GPU에 해당 batch의 input과 target을 올리고\n",
        "\n",
        "    optimizer.zero_grad()                   # 이전 epoch에서 계산된 기울기를 초기화\n",
        "    outputs = simple_model(inputs).view(-1) # 모델의 예측 계산 & 1차원 텐서로 변환\n",
        "    loss = criterion(outputs, targets)      # 손실값 계산\n",
        "    loss.backward()                         # 손실값을 토대로 각 파라미터 업데이트에 필요한 기울기 계산\n",
        "\n",
        "    optimizer.step()                        # 계산된 기울기를 바탕으로 파라미터 업데이트\n",
        "  print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bmMyiNepaK2",
        "outputId": "4e0174f6-3edc-41e7-cc7a-aac991e5b8e9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.168012335896492\n",
            "Epoch 2, Loss: 0.15463373064994812\n",
            "Epoch 3, Loss: 0.14142407476902008\n",
            "Epoch 4, Loss: 0.1285470575094223\n",
            "Epoch 5, Loss: 0.11636266857385635\n",
            "Epoch 6, Loss: 0.1052008792757988\n",
            "Epoch 7, Loss: 0.09525743871927261\n",
            "Epoch 8, Loss: 0.08658034354448318\n",
            "Epoch 9, Loss: 0.07910498231649399\n",
            "Epoch 10, Loss: 0.07270035147666931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "사전 학습된 모델을 사용해서 첫 Epoch부터 loss가 매우 낮은 상태이며 학습을 진행한 이후 사전학습 Embedding model을 사용하지 않은 것에 비해 loss가 더 낮아졌다"
      ],
      "metadata": {
        "id": "qKAnS5ikpe4Z"
      }
    }
  ]
}